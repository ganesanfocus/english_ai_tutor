<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>English Speaking Practice with AI</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            max-width: 700px;
            width: 100%;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 30px;
            font-size: 2.2em;
        }

        .setup-section {
            background: #f0f8ff;
            padding: 20px;
            border-radius: 12px;
            margin-bottom: 20px;
            border-left: 4px solid #4a90e2;
        }

        .setup-section h3 {
            color: #2c5aa0;
            margin-bottom: 10px;
        }

        .setup-section ol {
            margin-left: 20px;
            color: #555;
            list-style-type: decimal;
        }

        .setup-section li {
            margin: 5px 0;
        }

        .connection-status {
            display: flex;
            align-items: center;
            gap: 10px;
            margin: 15px 0;
            padding: 10px;
            border-radius: 8px;
        }

        .connection-status.connected {
            background: #d4edda;
            color: #155724;
        }

        .connection-status.disconnected {
            background: #f8d7da;
            color: #721c24;
        }
        
        .practice-section {
            margin-bottom: 30px;
        }

        .practice-prompt {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 12px;
            margin-bottom: 20px;
            border-left: 4px solid #667eea;
        }

        .practice-prompt h3 {
            color: #333;
            margin-bottom: 10px;
        }

        .practice-prompt p {
            color: #666;
            line-height: 1.6;
        }

        .controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin: 20px 0;
            flex-wrap: wrap;
        }

        button {
            background: #667eea;
            color: white;
            border: none;
            padding: 15px 25px;
            border-radius: 25px;
            font-size: 16px;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        button:hover:not(:disabled) {
            background: #5a6fd8;
            transform: translateY(-2px);
        }

        button:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
        }

        .secondary-btn {
            background: #6c757d;
        }

        .secondary-btn:hover:not(:disabled) {
            background: #5a6268;
        }

        .recording-indicator {
            display: none;
            text-align: center;
            color: #e74c3c;
            font-weight: bold;
            margin: 20px 0;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .processing-indicator {
            display: none;
            text-align: center;
            color: #f39c12;
            font-weight: bold;
            margin: 20px 0;
        }

        .feedback-section {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 12px;
            margin-top: 20px;
            display: none;
        }

        .feedback-section h3 {
            color: #333;
            margin-bottom: 15px;
        }

        .transcript {
            background: white;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 0;
            border: 1px solid #ddd;
            word-wrap: break-word;
        }

        .ai-feedback {
            background: #e8f4fd;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            border-left: 4px solid #4a90e2;
            white-space: pre-wrap; /* Preserve formatting from the AI */
        }

        .status {
            text-align: center;
            padding: 10px;
            margin: 10px 0;
            border-radius: 8px;
        }

        .status.success {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }

        .status.error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }

        .status.warning {
            background: #fff3cd;
            color: #856404;
            border: 1px solid #ffeaa7;
        }
        
        .audio-upload {
            background: #fff;
            border: 2px dashed #ddd;
            border-radius: 12px;
            padding: 20px;
            text-align: center;
            margin: 20px 0;
            transition: border-color 0.3s;
        }

        .audio-upload:hover {
            border-color: #667eea;
        }

        .audio-upload input {
            display: none;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ English Practice with AI</h1>
        
        <div class="setup-section">
            <h3>üîß Setup Instructions:</h3>
            <ol>
                <li>Open **LM Studio** and load a model (e.g., Llama 3.2 3B Instruct)</li>
                <li>Start the **local server** in LM Studio (usually runs on port 1234)</li>
                <li>Start your Flask backend server on port 5000</li>
                <li>Click **"Test Connection"** below</li>
            </ol>
            
            <div class="connection-status disconnected" id="connectionStatus">
                <span>üî¥</span>
                <span>AI Server: Not Connected</span>
                <button onclick="testConnection()" class="secondary-btn">Test Connection</button>
            </div>
        </div>

        <div class="practice-section">
            <div class="practice-prompt">
                <h3>Practice Prompt:</h3>
                <p id="promptText">Tell me about your favorite hobby and why you enjoy it.</p>
                <button onclick="getNewPrompt()">Get New Prompt</button>
            </div>

            <div class="controls">
                <button id="startBtn" onclick="startRecording()">
                    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-mic"><path d="M12 2a3 3 0 0 0-3 3v7a3 3 0 0 0 6 0V5a3 3 0 0 0-3-3Z"/><path d="M19 10v2a7 7 0 0 1-14 0v-2"/><line x1="12" x2="12" y1="19" y2="22"/></svg>
                    Record & Analyze
                </button>
                <button id="stopBtn" onclick="stopRecording()" disabled>
                    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-square"><rect width="18" height="18" x="3" y="3" rx="2"/></svg>
                    Stop Recording
                </button>
            </div>
            
            <div class="audio-upload">
                <p>Or upload an audio file:</p>
                <input type="file" id="audioFile" accept="audio/*" onchange="handleFileUpload()">
                <button onclick="document.getElementById('audioFile').click()">
                    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-folder-input"><path d="M20 20a2 2 0 0 0 2-2V8a2 2 0 0 0-2-2h-7.9a2 2 0 0 1-1.69-.9L9.6 3.9A2 2 0 0 0 7.93 3H4a2 2 0 0 0-2 2v13a2 2 0 0 0 2 2h4"/><path d="M12 13v7"/><path d="m15 16-3-3-3 3"/></svg>
                    Upload Audio
                </button>
            </div>

            <div class="recording-indicator" id="recordingIndicator">
                üî¥ Recording... Speak clearly and naturally!
            </div>

            <div class="processing-indicator" id="processingIndicator">
                ‚öôÔ∏è Processing your speech with AI...
            </div>
        </div>

        <div class="feedback-section" id="feedbackSection">
            <h3>üìù AI Analysis Results</h3>
            
            <div class="transcript" id="transcript">
                <h4>What you said:</h4>
                <p id="transcriptText"></p>
            </div>

            <div class="ai-feedback" id="aiFeedback">
                <h4>ü§ñ AI Feedback:</h4>
                <p id="feedbackText"></p>
            </div>

            <div class="controls">
                <button onclick="speakFeedback()" id="speakBtn">
                    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-volume-2"><polygon points="11 5 6 9 2 9 2 15 6 15 11 19 11 5"/><path d="M15.54 8.46a5 5 0 0 1 0 7.07"/><path d="M19.07 4.93a10 10 0 0 1 0 14.14"/></svg>
                    Listen to Feedback
                </button>
                <button onclick="startNewPractice()" class="secondary-btn">
                    <svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-rotate-cw"><path d="M21 12a9 9 0 1 1-9-9c2.52 0 4.93 1.03 6.63 2.87"/><path d="M12 3v7h7"/></svg>
                    New Practice
                </button>
            </div>
        </div>

        <div id="status"></div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let currentFeedback = "";
        let lmStudioConnected = false;

        const prompts = [
            "Tell me about your favorite hobby and why you enjoy it.",
            "Describe your typical day from morning to evening.",
            "What's the most interesting place you've ever visited?",
            "Explain how to make your favorite dish.",
            "What are your goals for the next five years?",
            "Describe someone who has influenced your life.",
            "What's your opinion about social media and its impact?",
            "Tell me about a book or movie that changed your perspective.",
            "How do you handle stressful situations in your life?",
            "What would you do if you won a million dollars?",
            "Describe your dream job and why it appeals to you.",
            "What's the biggest challenge you've overcome?",
            "How has technology changed our daily lives?",
            "What advice would you give to your younger self?"
        ];

        // 1. Dynamic model detection for LM Studio
        async function testConnection() {
            try {
                showStatus('Testing LM Studio connection...', 'warning');
                
                const response = await fetch('/models'); // Use your Flask route
                
                if (response.ok) {
                    const data = await response.json();
                    const modelName = data.data?.[0]?.id || 'Unknown model';
                    lmStudioConnected = true;
                    updateConnectionStatus(true, modelName);
                    showStatus(`‚úÖ LM Studio connected with model: ${modelName}`, 'success');
                    
                    // Store the actual model name for use in AI requests
                    window.currentModel = modelName;
                } else {
                    throw new Error('Connection failed');
                }
            } catch (error) {
                lmStudioConnected = false;
                updateConnectionStatus(false);
                showStatus('‚ùå Cannot connect to LM Studio. Make sure it\'s running on port 1234.', 'error');
            }
        }


        function updateConnectionStatus(connected, modelName = '') {
            const status = document.getElementById('connectionStatus');
            if (connected) {
                status.className = 'connection-status connected';
                status.innerHTML = `<span>üü¢</span><span>AI Server: Connected ${modelName ? `(${modelName})` : ''}</span>`;
            } else {
                status.className = 'connection-status disconnected';
                status.innerHTML = `<span>üî¥</span><span>AI Server: Not Connected</span><button onclick="testConnection()" class="secondary-btn">Test Connection</button>`;
            }
        }

        function getNewPrompt() {
            const randomPrompt = prompts[Math.floor(Math.random() * prompts.length)];
            document.getElementById('promptText').textContent = randomPrompt;
            document.getElementById('feedbackSection').style.display = 'none';
            document.getElementById('transcriptText').textContent = '';
            document.getElementById('feedbackText').textContent = '';
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    processAudio(audioBlob);
                };

                mediaRecorder.start();
                isRecording = true;

                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                document.getElementById('recordingIndicator').style.display = 'block';
                showStatus('üé§ Recording started! Speak clearly and naturally.', 'success');

            } catch (error) {
                console.error('Error accessing microphone:', error);
                showStatus('‚ùå Could not access microphone. Please allow microphone permissions.', 'error');
            }
        }

        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                isRecording = false;

                document.getElementById('startBtn').disabled = false;
                document.getElementById('stopBtn').disabled = true;
                document.getElementById('recordingIndicator').style.display = 'none';
            }
        }

        // 2. File validation before upload
        function handleFileUpload() {
            const fileInput = document.getElementById('audioFile');
            const file = fileInput.files[0];
            
            if (file) {
                // Validate file size (16MB limit)
                if (file.size > 16 * 1024 * 1024) {
                    showStatus('‚ùå File too large. Maximum size is 16MB.', 'error');
                    fileInput.value = ''; // Clear the input
                    return;
                }
                
                // Validate file type
                const allowedTypes = ['audio/mp3', 'audio/wav', 'audio/m4a', 'audio/ogg'];
                if (!allowedTypes.includes(file.type) && !file.name.match(/\.(mp3|wav|m4a|ogg)$/i)) {
                    showStatus('‚ùå Invalid file type. Please use MP3, WAV, M4A, or OGG.', 'error');
                    fileInput.value = ''; // Clear the input
                    return;
                }
                
                showStatus('üìÅ Processing uploaded audio file...', 'warning');
                processAudio(file);
                
                // Clear the file input after processing starts
                setTimeout(() => {
                    fileInput.value = '';
                }, 1000);
            }
        }


        async function processAudio(audioBlob) {
            document.getElementById('processingIndicator').style.display = 'block';
            showStatus('üîÑ Step 1: Converting speech to text...', 'warning');

            try {
                // Send to Flask backend for Whisper processing
                const transcript = await transcribeWithWhisper(audioBlob);
                
                showStatus('üîÑ Step 2: Analyzing with LM Studio AI...', 'warning');
                
                if (!lmStudioConnected) {
                    await testConnection();
                }

                let analysis;
                if (lmStudioConnected) {
                    analysis = await getAIFeedback(transcript);
                } else {
                    analysis = analyzeBasicGrammar(transcript);
                    showStatus('‚ö†Ô∏è Using basic analysis. Connect LM Studio for AI-powered feedback.', 'warning');
                }

                displayResults(transcript, analysis);

            } catch (error) {
                console.error('Error processing audio:', error);
                showStatus('‚ùå Error processing audio. Please try again.', 'error');
            } finally {
                document.getElementById('processingIndicator').style.display = 'none';
            }
        }

        // Send audio to Flask backend for Whisper transcription
        // 4. Better error handling for audio processing
        async function transcribeWithWhisper(audioBlob) {
            try {
                const formData = new FormData();
                formData.append('audio', audioBlob, 'recording.wav');

                const response = await fetch('/transcribe', {
                    method: 'POST',
                    body: formData
                });

                const result = await response.json();

                if (!response.ok) {
                    throw new Error(result.error || `Server error: ${response.status}`);
                }
                
                if (result.success && result.transcript) {
                    if (result.transcript.trim().length < 10) {
                        showStatus('‚ö†Ô∏è Very short transcript detected. Try speaking longer or closer to the microphone.', 'warning');
                    }
                    return result.transcript;
                } else {
                    throw new Error(result.error || 'Transcription failed - no text detected');
                }

            } catch (error) {
                console.error('Whisper transcription error:', error);
                showStatus(`‚ùå Transcription error: ${error.message}`, 'error');
                throw error;
            }
        }

        // 3. Use dynamic model name in AI requests
        async function getAIFeedback(transcript) {
            try {
                const modelName = window.currentModel || "llama-3.2-3b-instruct"; // Fallback
                
                const prompt = `You are an English language teacher helping a student improve their speaking skills. 
        Please analyze this transcript and provide helpful feedback:
        "${transcript}"

        Focus on:
        1. Grammar mistakes and corrections
        2. Word choice improvements  
        3. Sentence structure suggestions
        4. Pronunciation tips (if obvious from text)
        5. Overall communication effectiveness

        Be encouraging but specific about improvements. Format your response clearly with numbered points.`;

                const response = await fetch('http://localhost:1234/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        model: modelName, // Use detected model
                        messages: [
                            {
                                role: "system",
                                content: "You are a helpful and expert English language teacher."
                            },
                            {
                                role: "user", 
                                content: prompt
                            }
                        ],
                        temperature: 0.7,
                        max_tokens: 500
                    })
                });

                if (!response.ok) {
                    throw new Error(`LM Studio request failed: ${response.status}`);
                }

                const data = await response.json();
                return data.choices[0].message.content;

            } catch (error) {
                console.error('LM Studio error:', error);
                lmStudioConnected = false; // Reset connection status
                updateConnectionStatus(false);
                showStatus(`‚ùå AI analysis failed: ${error.message}. Using basic analysis.`, 'error');
                return analyzeBasicGrammar(transcript);
            }
        }

        function analyzeBasicGrammar(transcript) {
            // Fallback analysis when LM Studio isn't available
            // This is a simple, rule-based approach.
            const mistakes = [
                { wrong: "have completed", correct: "completed" },
                { wrong: "in Coimbatore KIT College", correct: "at KIT College in Coimbatore" },
                { wrong: "in 2019 from January 1st", correct: "on January 1, 2019" },
                { wrong: "a fresh air", correct: "a fresher" },
                { wrong: "100 application development", correct: "Android application development" },
                { wrong: "under 6 months course", correct: "a six-month course" },
                { wrong: "we started in my company they changed their language", correct: "my company changed its primary language" },
                { wrong: "Python Floss", correct: "Python Flask" },
                { wrong: "landed in", correct: "transitioned to" },
                { wrong: "I promoted to", correct: "I was promoted to" },
                { wrong: "had 4 team members", correct: "had a team of 4 members" }
            ];

            let feedback = "### Basic Grammar Feedback:\n\n";
            let foundMistakes = 0;

            mistakes.forEach(mistake => {
                if (transcript.includes(mistake.wrong)) {
                    foundMistakes++;
                    feedback += `${foundMistakes}. **Correction:** "${mistake.wrong}" should be "${mistake.correct}".\n`;
                }
            });

            if (foundMistakes === 0) {
                feedback = "Great job! I didn't detect any of these common grammar mistakes. Keep practicing!";
            } else {
                feedback += `\n**Keep up the great work!** Focusing on these ${foundMistakes} points will make your English even more fluent.`;
            }

            return feedback;
        }

        function displayResults(transcript, feedback) {
            document.getElementById('transcriptText').textContent = transcript;
            document.getElementById('feedbackText').textContent = feedback;
            document.getElementById('feedbackSection').style.display = 'block';
            currentFeedback = feedback;
            
            showStatus('‚úÖ Analysis complete! Review your feedback below.', 'success');
        }

        function speakFeedback() {
            if ('speechSynthesis' in window && currentFeedback) {
                speechSynthesis.cancel(); // Stop any current speech
                
                const utterance = new SpeechSynthesisUtterance(currentFeedback);
                utterance.rate = 0.8;
                utterance.pitch = 1;
                utterance.volume = 1;
                
                const voices = speechSynthesis.getVoices();
                const englishVoice = voices.find(voice => 
                    voice.lang.includes('en') && 
                    (voice.name.includes('US') || voice.name.includes('UK') || voice.name.includes('English'))
                );
                if (englishVoice) {
                    utterance.voice = englishVoice;
                }

                speechSynthesis.speak(utterance);
                showStatus('üîä Playing audio feedback...', 'success');
            }
        }

        function startNewPractice() {
            document.getElementById('feedbackSection').style.display = 'none';
            getNewPrompt();
            showStatus('Ready for a new practice session!', 'success');
        }

        function showStatus(message, type) {
            const status = document.getElementById('status');
            status.textContent = message;
            status.className = `status ${type}`;
        }

        window.addEventListener('load', () => {
            if ('speechSynthesis' in window) {
                speechSynthesis.getVoices();
                speechSynthesis.addEventListener('voiceschanged', () => {
                    speechSynthesis.getVoices();
                });
            }
            
            setTimeout(testConnection, 1000);
        });
    </script>
</body>
</html>