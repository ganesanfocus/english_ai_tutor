<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>English Speaking Practice with AI</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            max-width: 700px;
            width: 100%;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 30px;
            font-size: 2.2em;
        }

        .setup-section {
            background: #f0f8ff;
            padding: 20px;
            border-radius: 12px;
            margin-bottom: 20px;
            border-left: 4px solid #4a90e2;
        }

        .setup-section h3 {
            color: #2c5aa0;
            margin-bottom: 10px;
        }

        .setup-section ol {
            margin-left: 20px;
            color: #555;
            list-style-type: decimal;
        }

        .setup-section li {
            margin: 5px 0;
        }

        .connection-status {
            display: flex;
            align-items: center;
            gap: 10px;
            margin: 15px 0;
            padding: 10px;
            border-radius: 8px;
        }

        .connection-status.connected {
            background: #d4edda;
            color: #155724;
        }

        .connection-status.disconnected {
            background: #f8d7da;
            color: #721c24;
        }
        
        .practice-section {
            margin-bottom: 30px;
        }

        .practice-prompt {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 12px;
            margin-bottom: 20px;
            border-left: 4px solid #667eea;
        }

        .practice-prompt h3 {
            color: #333;
            margin-bottom: 10px;
        }

        .practice-prompt p {
            color: #666;
            line-height: 1.6;
        }

        .controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            margin: 20px 0;
            flex-wrap: wrap;
        }

        button {
            background: #667eea;
            color: white;
            border: none;
            padding: 15px 25px;
            border-radius: 25px;
            font-size: 16px;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            gap: 8px;
        }

        button:hover:not(:disabled) {
            background: #5a6fd8;
            transform: translateY(-2px);
        }

        button:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
        }

        .secondary-btn {
            background: #6c757d;
        }

        .secondary-btn:hover:not(:disabled) {
            background: #5a6268;
        }

        .recording-indicator {
            display: none;
            text-align: center;
            color: #e74c3c;
            font-weight: bold;
            margin: 20px 0;
            animation: pulse 1.5s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.5; }
        }

        .processing-indicator {
            display: none;
            text-align: center;
            color: #f39c12;
            font-weight: bold;
            margin: 20px 0;
        }

        .feedback-section {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 12px;
            margin-top: 20px;
            display: none;
        }

        .feedback-section h3 {
            color: #333;
            margin-bottom: 15px;
        }

        .transcript {
            background: white;
            padding: 15px;
            border-radius: 8px;
            margin: 10px 0;
            border: 1px solid #ddd;
            word-wrap: break-word;
        }

        .ai-feedback {
            background: #e8f4fd;
            padding: 15px;
            border-radius: 8px;
            margin: 15px 0;
            border-left: 4px solid #4a90e2;
            white-space: pre-wrap;
        }

        .status {
            text-align: center;
            padding: 10px;
            margin: 10px 0;
            border-radius: 8px;
        }

        .status.success {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }

        .status.error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }

        .status.warning {
            background: #fff3cd;
            color: #856404;
            border: 1px solid #ffeaa7;
        }
        
        .audio-upload {
            background: #fff;
            border: 2px dashed #ddd;
            border-radius: 12px;
            padding: 20px;
            text-align: center;
            margin: 20px 0;
            transition: border-color 0.3s;
        }

        .audio-upload:hover {
            border-color: #667eea;
        }

        .audio-upload input[type="file"] {
            display: none;
        }

        .audio-upload label {
            cursor: pointer;
            color: #667eea;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ English Practice with AI</h1>

        <div class="setup-section">
            <h3>üîß Setup Instructions:</h3>
            <ol>
                <li>Open <strong>LM Studio</strong> and load a model (e.g., Deepseek Model)</li>
                <li>Start the <strong>local server</strong> in LM Studio (usually runs on port 1234)</li>
                <li>Start your Flask backend server on port 5000</li>
                <li>Click <strong>"Test Connection"</strong> below</li>
            </ol>
            <div id="connectionStatus" class="connection-status disconnected">
                <span>‚ö™</span>
                <span id="statusText">AI Server: Not tested yet</span>
            </div>
        </div>

        <div class="practice-section">
            <div class="practice-prompt">
                <h3>Practice Prompt:</h3>
                <p id="promptText">What's the most interesting place you've ever visited?</p>
                <button onclick="getNewPrompt()" class="secondary-btn">Get New Prompt</button>
            </div>

            <div class="controls">
                <button id="recordBtn" onclick="toggleRecording()">
                    üé§ Record & Analyze
                </button>
                <button id="stopBtn" onclick="stopRecording()" disabled class="secondary-btn">
                    ‚èπ Stop Recording
                </button>
            </div>

            <div id="recordingIndicator" class="recording-indicator">
                üî¥ Recording... Speak clearly!
            </div>

            <div id="processingIndicator" class="processing-indicator">
                ‚è≥ Processing your speech...
            </div>

            <div class="audio-upload">
                <p style="color: #666; margin-bottom: 10px;">Or upload an audio file:</p>
                <input type="file" id="audioFileInput" accept="audio/*" onchange="handleFileUpload(event)">
                <label for="audioFileInput">üìÅ Upload Audio</label>
            </div>

            <div id="feedbackSection" class="feedback-section">
                <h3>üìã AI Analysis Results</h3>
                
                <h4>What you said:</h4>
                <div class="transcript" id="transcriptText"></div>

                <h4>üìä AI Feedback:</h4>
                <div class="ai-feedback" id="feedbackText"></div>

                <div class="controls">
                    <button onclick="speakFeedback()">üîä Listen to Feedback</button>
                    <button onclick="startNewPractice()" class="secondary-btn">üîÑ New Practice</button>
                </div>
            </div>
        </div>

        <div id="status" class="status"></div>
    </div>

    <script>
        let mediaRecorder;
        let audioChunks = [];
        let isRecording = false;
        let lmStudioConnected = false;
        let currentFeedback = '';

        async function testConnection() {
            try {
                // FIXED: Call Flask backend instead of LM Studio directly
                const response = await fetch('/models', {
                    method: 'GET',
                });
                
                if (response.ok) {
                    const data = await response.json();
                    if (data.error) {
                        updateConnectionStatus(false);
                        showStatus('LM Studio not available - using improved grammar checker', 'warning');
                    } else {
                        const modelName = data.data?.[0]?.id || 'local-model';
                        window.currentModel = modelName;
                        lmStudioConnected = true;
                        updateConnectionStatus(true, modelName);
                        showStatus(`‚úÖ Connected to LM Studio (${modelName})`, 'success');
                    }
                } else {
                    updateConnectionStatus(false);
                    showStatus('LM Studio not available - using improved grammar checker', 'warning');
                }
            } catch (error) {
                console.error('Connection test error:', error);
                updateConnectionStatus(false);
                showStatus('LM Studio not available - using improved grammar checker', 'warning');
            }
        }

        function updateConnectionStatus(connected, modelName = '') {
            const statusDiv = document.getElementById('connectionStatus');
            const statusText = document.getElementById('statusText');
            
            if (connected) {
                statusDiv.className = 'connection-status connected';
                statusText.textContent = `‚úÖ AI Server: Connected (${modelName})`;
            } else {
                statusDiv.className = 'connection-status disconnected';
                statusText.textContent = '‚ö†Ô∏è LM Studio disconnected - using improved grammar checker';
            }
        }

        async function getNewPrompt() {
            try {
                const response = await fetch('/prompts');
                const data = await response.json();
                document.getElementById('promptText').textContent = data.prompt;
                showStatus('New prompt loaded!', 'success');
            } catch (error) {
                showStatus('Error loading prompt', 'error');
            }
        }

        async function toggleRecording() {
            if (!isRecording) {
                await startRecording();
            }
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];

                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };

                mediaRecorder.onstop = async () => {
                    const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                    await processAudio(audioBlob);
                    stream.getTracks().forEach(track => track.stop());
                };

                mediaRecorder.start();
                isRecording = true;

                document.getElementById('recordBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                document.getElementById('recordingIndicator').style.display = 'block';
                
                showStatus('üé§ Recording started! Speak clearly...', 'success');

            } catch (error) {
                showStatus('‚ùå Microphone access denied. Please allow microphone access.', 'error');
            }
        }

        function stopRecording() {
            if (mediaRecorder && isRecording) {
                mediaRecorder.stop();
                isRecording = false;

                document.getElementById('recordBtn').disabled = false;
                document.getElementById('stopBtn').disabled = true;
                document.getElementById('recordingIndicator').style.display = 'none';
            }
        }

        async function handleFileUpload(event) {
            const file = event.target.files[0];
            if (file) {
                const allowedTypes = ['audio/mp3', 'audio/wav', 'audio/m4a', 'audio/ogg'];
                if (!allowedTypes.includes(file.type) && !file.name.match(/\.(mp3|wav|m4a|ogg)$/i)) {
                    showStatus('‚ùå Invalid file type. Please use MP3, WAV, M4A, or OGG.', 'error');
                    event.target.value = '';
                    return;
                }
                
                showStatus('üìÅ Processing uploaded audio file...', 'warning');
                processAudio(file);
                
                setTimeout(() => {
                    event.target.value = '';
                }, 1000);
            }
        }

        async function processAudio(audioBlob) {
            document.getElementById('processingIndicator').style.display = 'block';
            showStatus('üîÑ Step 1: Converting speech to text...', 'warning');

            try {
                const transcript = await transcribeWithWhisper(audioBlob);
                
                showStatus('üîÑ Step 2: Analyzing grammar...', 'warning');
                
                // FIXED: Always call Flask /analyze endpoint
                const analysis = await getAIFeedbackFromFlask(transcript);

                displayResults(transcript, analysis);

            } catch (error) {
                console.error('Error processing audio:', error);
                showStatus('‚ùå Error processing audio. Please try again.', 'error');
            } finally {
                document.getElementById('processingIndicator').style.display = 'none';
            }
        }

        async function transcribeWithWhisper(audioBlob) {
            try {
                const formData = new FormData();
                formData.append('audio', audioBlob, 'recording.wav');

                const response = await fetch('/transcribe', {
                    method: 'POST',
                    body: formData
                });

                const result = await response.json();

                if (!response.ok) {
                    throw new Error(result.error || `Server error: ${response.status}`);
                }
                
                if (result.success && result.transcript) {
                    if (result.transcript.trim().length < 10) {
                        showStatus('‚ö†Ô∏è Very short transcript detected. Try speaking longer.', 'warning');
                    }
                    return result.transcript;
                } else {
                    throw new Error(result.error || 'Transcription failed');
                }

            } catch (error) {
                console.error('Whisper transcription error:', error);
                showStatus(`‚ùå Transcription error: ${error.message}`, 'error');
                throw error;
            }
        }

        // FIXED: New function that calls Flask /analyze endpoint
        async function getAIFeedbackFromFlask(transcript) {
            try {
                const response = await fetch('/analyze', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        transcript: transcript
                    })
                });

                if (!response.ok) {
                    throw new Error(`Analysis request failed: ${response.status}`);
                }

                const data = await response.json();
                
                if (data.success && data.feedback) {
                    // Update connection status based on source
                    if (data.source === 'ai') {
                        lmStudioConnected = true;
                        updateConnectionStatus(true, window.currentModel || 'local-model');
                    } else {
                        lmStudioConnected = false;
                        updateConnectionStatus(false);
                    }
                    
                    return data.feedback;
                } else {
                    throw new Error(data.error || 'Analysis failed');
                }

            } catch (error) {
                console.error('Analysis error:', error);
                showStatus(`‚ùå Analysis failed: ${error.message}`, 'error');
                throw error;
            }
        }

        function displayResults(transcript, feedback) {
            document.getElementById('transcriptText').textContent = transcript;
            document.getElementById('feedbackText').textContent = feedback;
            document.getElementById('feedbackSection').style.display = 'block';
            currentFeedback = feedback;
            
            showStatus('‚úÖ Analysis complete! Review your feedback below.', 'success');
        }

        function speakFeedback() {
            if ('speechSynthesis' in window && currentFeedback) {
                speechSynthesis.cancel();
                
                const utterance = new SpeechSynthesisUtterance(currentFeedback);
                utterance.rate = 0.8;
                utterance.pitch = 1;
                utterance.volume = 1;
                
                const voices = speechSynthesis.getVoices();
                const englishVoice = voices.find(voice => 
                    voice.lang.includes('en') && 
                    (voice.name.includes('US') || voice.name.includes('UK') || voice.name.includes('English'))
                );
                if (englishVoice) {
                    utterance.voice = englishVoice;
                }

                speechSynthesis.speak(utterance);
                showStatus('üîä Playing audio feedback...', 'success');
            }
        }

        function startNewPractice() {
            document.getElementById('feedbackSection').style.display = 'none';
            getNewPrompt();
            showStatus('Ready for a new practice session!', 'success');
        }

        function showStatus(message, type) {
            const status = document.getElementById('status');
            status.textContent = message;
            status.className = `status ${type}`;
        }

        window.addEventListener('load', () => {
            if ('speechSynthesis' in window) {
                speechSynthesis.getVoices();
                speechSynthesis.addEventListener('voiceschanged', () => {
                    speechSynthesis.getVoices();
                });
            }
            
            setTimeout(testConnection, 1000);
        });
    </script>
</body>
</html>